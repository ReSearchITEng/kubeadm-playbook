#####
# ADDONS # uncomment/ add the desired ones.
#k8s_addons_urls:
  # - https://github.com/kubernetes/kubernetes/raw/master/cluster/addons/node-problem-detector/npd.yaml # rbac ready
#####

###################
## HELM & CHARTS ##
###################
helm:
  helm_version: v2.14.3 # or "latest" #https://github.com/kubernetes/helm/releases
  install_script_url: 'https://github.com/kubernetes/helm/raw/master/scripts/get' 
  repos: ## stable repo is installed by helm by default, no need for its entry here, add only new ones
    - { name: incubator, url: 'http://storage.googleapis.com/kubernetes-charts-incubator' }

  packages_list: # when not defined, namespace defaults to "default" namespace
  ### List helm charts you wish pre-installed every time cluster is deployed:

########################
## Monitoring: prometheus, using coreos's prometheus-operator, which includes: grafana, alertmanager, prometheus.
## PROMETHEUS Operator #
########################
# k delete crd alertmanagers.monitoring.coreos.com prometheusrules.monitoring.coreos.com servicemonitors.monitoring.coreos.com prometheuses.monitoring.coreos.com podmonitors.monitoring.coreos.com
# helm install --name prometheus stable/prometheus-operator --namespace monitoring 
    - { name: prometheus, repo: stable/prometheus-operator, namespace: monitoring, options: '--set prometheusOperator.nodeSelector."node\-role\.kubernetes\.io/infra=" --set prometheusOperator.tolerations[0].effect=NoSchedule,prometheusOperator.tolerations[0].key="node-role.kubernetes.io/infra" --set prometheusOperator.tolerations[1].effect=PreferNoSchedule,prometheusOperator.tolerations[1].key="node-role.kubernetes.io/infra" --set prometheus.prometheusSpec.nodeSelector."node\-role\.kubernetes\.io/infra=" --set prometheus.prometheusSpec.tolerations[0].effect=NoSchedule,prometheus.prometheusSpec.tolerations[0].key="node-role.kubernetes.io/infra" --set prometheus.prometheusSpec.tolerations[1].effect=PreferNoSchedule,prometheus.prometheusSpec.tolerations[1].key="node-role.kubernetes.io/infra" --set alertmanager.alertmanagerSpec.nodeSelector."node\-role\.kubernetes\.io/infra=" --set alertmanager.alertmanagerSpec.tolerations[0].effect=NoSchedule,alertmanager.alertmanagerSpec.tolerations[0].key="node-role.kubernetes.io/infra" --set alertmanager.alertmanagerSpec.tolerations[1].effect=PreferNoSchedule,alertmanager.alertmanagerSpec.tolerations[1].key="node-role.kubernetes.io/infra" --set grafana.nodeSelector."node\-role\.kubernetes\.io/infra=" --set grafana.tolerations[0].effect=NoSchedule,grafana.tolerations[0].key="node-role.kubernetes.io/infra" --set grafana.tolerations[1].effect=PreferNoSchedule,grafana.tolerations[1].key="node-role.kubernetes.io/infra" --set prometheus.ingress.enabled=True --set prometheus.ingress.hosts[0]=prometheus.{{ custom.networking.dnsDomain }} --set grafana.ingress.enabled=True --set grafana.ingress.hosts[0]=grafana.{{ custom.networking.dnsDomain }} --set alertmanager.ingress.enabled=True --set alertmanager.ingress.hosts[0]=alertmanager.{{ custom.networking.dnsDomain }} --set prometheusOperator.image.repository={{ images_repo | default ("quay.io") }}/coreos/prometheus-operator --set prometheusOperator.configmapReloadImage.repository={{ images_repo | default ("quay.io") }}/coreos/configmap-reload --set prometheusOperator.prometheusConfigReloaderImage.repository={{ images_repo | default ("quay.io") }}/coreos/prometheus-config-reloader --set prometheus.prometheusSpec.image.repository={{ images_repo | default ("quay.io") }}/prometheus/prometheus --set alertmanager.alertmanagerSpec.image.repository={{ images_repo | default ("quay.io") }}/prometheus/alertmanager --set prometheusOperator.hyperkubeImage.repository={{ images_repo | default ("k8s.gcr.io") }}/hyperkube --set grafana.image.repository={{ images_repo | default ("docker.io") }}/grafana/grafana --set kube-state-metrics.image.repository={{ images_repo | default ("quay.io") }}/coreos/kube-state-metrics --set kube-state-metrics.tolerations[0].effect=NoSchedule,kube-state-metrics.tolerations[0].key="node-role.kubernetes.io/infra" --set kube-state-metrics.tolerations[1].effect=PreferNoSchedule,kube-state-metrics.tolerations[1].key="node-role.kubernetes.io/infra" --set kube-state-metrics.nodeSelector."node\-role\.kubernetes\.io/infra=" --set prometheus-node-exporter.image.repository={{ images_repo | default ("quay.io") }}/prometheus/node-exporter ' }

    #- { name: prometheus, repo: stable/prometheus-operator, namespace: monitoring, options: '--set prometheus.ingress.enabled=True --set prometheus.ingress.hosts[0]=prometheus.{{ custom.networking.dnsDomain }} --set grafana.ingress.enabled=True --set grafana.ingress.hosts[0]=grafana.{{ custom.networking.dnsDomain }} --set alertmanager.ingress.enabled=True --set alertmanager.ingress.hosts[0]=alertmanager.{{ custom.networking.dnsDomain }} ' }

################
#### Heapster ##
################
    - { name: heapster, repo: stable/heapster, namespace: kube-system, options: '--set service.nameOverride=heapster,rbac.create=true --set nodeSelector."node\-role\.kubernetes\.io/infra=" --set tolerations[0].effect=NoSchedule,tolerations[0].key="node-role.kubernetes.io/infra" --set tolerations[1].effect=PreferNoSchedule,tolerations[1].key="node-role.kubernetes.io/infra" --set image.repository={{ images_repo | default ("k8s.gcr.io") }}/heapster-amd64 --set resizer.image.repository={{ images_repo | default ("k8s.gcr.io") }}/addon-resizer --set resizer.enabled=False ' }
# --set resizer.enabled=False ->> this is not working with taints due to some bug, thefore disabling it for now.
#    - { name: heapster, repo: stable/heapster, namespace: kube-system, options: '--set service.nameOverride=heapster,rbac.create=true' }

################
## DASHBOARD ###
################
    - { name: dashboard, repo: stable/kubernetes-dashboard, namespace: kube-system, options: '--set image.repository={{ images_repo | default ("k8s.gcr.io") }}/kubernetes-dashboard-amd64 --set rbac.create=True,ingress.enabled=True,ingress.hosts[0]=dashboard.{{ custom.networking.dnsDomain }},ingress.hosts[1]={{ custom.networking.masterha_fqdn | default (groups["primary-master"][0]) }},ingress.hosts[2]={{ groups["primary-master"][0] }} --set nodeSelector."node\-role\.kubernetes\.io/infra=" --set tolerations[0].effect=NoSchedule,tolerations[0].key="node-role.kubernetes.io/infra" --set tolerations[1].effect=PreferNoSchedule,tolerations[1].key="node-role.kubernetes.io/infra" --set rbac.create=True,rbac.clusterAdminRole=True --set enableInsecureLogin=True --set enableSkipLogin=True ' }
# For a learning/development --set rbac.clusterAdminRole=True with skip login and insecure might be acceptable, but not for real case scenarios!!!
# For in between, one can keep: rbac.clusterReadOnlyRole=True (if bug https://github.com/helm/charts/issues/15118 was solved)
# For a production, remove --set enableInsecureLogin=True --set enableSkipLogin=True --set rbac.clusterAdminRole=True

################
## Kured #######
## For restaring nodes when needed, in sequencial and proper manner
################
    - { name: kured, repo: stable/kured, namespace: kube-system, options: '--set extraArgs.period="0h07m0s" --set image.repository={{ images_repo | default ("docker.io") }}/weaveworks/kured ' }
#    - { name: kured, repo: stable/kured, namespace: kube-system, options: '--set extraArgs.period="0h07m0s"' }


################
## metallb #####
################
#    - { name: metallb, repo: stable/metallb, namespace: infra, options: '--set controller.nodeSelector."node\-role\.kubernetes\.io/infra=" --set controller.image.repository={{ images_repo | default ("docker.io") }}/metallb/controller --set speaker.nodeSelector."node\-role\.kubernetes\.io/infra=" --set speaker.image.repository={{ images_repo | default ("docker.io") }}/metallb/speaker --set prometheus.serviceMonitor.enabled=True --set prometheus.prometheusRule.enabled=True' }


####################
## NGINX INGRESS ###
####################
    ### Option 1 - Daemonset & NodePort :
    - { name: nginx-ingress, repo: stable/nginx-ingress, namespace: kube-system, options: '--set rbac.create=true,serviceAccount.create=true --set controller.stats.enabled=true,controller.metrics.enabled=true,controller.metrics.serviceMonitor.enabled=true --set controller.metrics.serviceMonitor.namespace=monitoring --set controller.metrics.serviceMonitor.additionalLabels.monitoring=prometheusoperator --set controller.tolerations[0].effect=NoSchedule,controller.tolerations[0].key="node-role.kubernetes.io/infra" --set controller.tolerations[1].effect=PreferNoSchedule,controller.tolerations[1].key="node-role.kubernetes.io/infra" --set controller.nodeSelector."node\-role\.kubernetes\.io/infra=" --set controller.kind=DaemonSet --set controller.service.type=NodePort --set controller.service.nodePorts.http=80 --set controller.service.nodePorts.https=443 --set controller.image.repository={{ images_repo | default ("quay.io") }}/kubernetes-ingress-controller/nginx-ingress-controller --set defaultBackend.image.repository={{ images_repo | default ("k8s.gcr.io") }}/defaultbackend-amd64 ' }
    # --set controller.service.externalTrafficPolicy="Local" # for better performance, when you have a LB for the ingress controllers (across all nodes with role label infra), add this as well, or use the useHostPort option below.

    ### Option 2 - DaemonSet & hostPort
    # - { name: nginx-ingress, repo: stable/nginx-ingress, namespace: kube-system, options: '--set rbac.create=true,serviceAccount.create=true --set controller.stats.enabled=true,controller.metrics.enabled=true,controller.metrics.serviceMonitor.enabled=true --set controller.metrics.serviceMonitor.namespace=monitoring --set controller.metrics.serviceMonitor.additionalLabels.monitoring=prometheusoperator --set controller.tolerations[0].effect=NoSchedule,controller.tolerations[0].key="node-role.kubernetes.io/infra" --set controller.tolerations[1].effect=PreferNoSchedule,controller.tolerations[1].key="node-role.kubernetes.io/infra" --set controller.nodeSelector."node\-role\.kubernetes\.io/infra=" --set controller.service.type=ClusterIP --set controller.kind=DaemonSet --set controller.daemonset.useHostPort=true --set controller.image.repository={{ images_repo | default ("quay.io") }}/kubernetes-ingress-controller/nginx-ingress-controller --set defaultBackend.image.repository={{ images_repo | default ("k8s.gcr.io") }}/defaultbackend-amd64 ' }

    ### Option 3 - Deployment & NodePort
    # - { name: nginx-ingress, repo: stable/nginx-ingress, namespace: kube-system, options: '--set rbac.create=true,serviceAccount.create=true --set controller.stats.enabled=true,controller.metrics.enabled=true,controller.metrics.serviceMonitor.enabled=true --set controller.metrics.serviceMonitor.namespace=monitoring --set controller.metrics.serviceMonitor.additionalLabels.monitoring=prometheusoperator --set controller.service.type=NodePort --set controller.service.nodePorts.http=80 --set controller.service.nodePorts.https=443  --set controller.tolerations[0].effect=NoSchedule,controller.tolerations[0].key="node-role.kubernetes.io/infra" --set controller.tolerations[1].effect=PreferNoSchedule,controller.tolerations[1].key="node-role.kubernetes.io/infra" --set controller.nodeSelector."node\-role\.kubernetes\.io/infra=" --set controller.image.repository={{ images_repo | default ("quay.io") }}/kubernetes-ingress-controller/nginx-ingress-controller --set defaultBackend.image.repository={{ images_repo | default ("k8s.gcr.io") }}/defaultbackend-amd64 --set controller.kind=Deployment ' }
# --set controller.service.externalTrafficPolicy="Local" # See notes above

#####
