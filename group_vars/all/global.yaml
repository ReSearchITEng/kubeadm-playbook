## global variables
##
## ansible 2.8+ accepts by default both python2 and python3
## for older (2.5->2.7), if you want to use python3, uncomment this:
# ansible_python_interpreter=/usr/bin/python3
## (the variable can also be defined per host if there is a need for mix)

## Defines mappings for the original gropus that were used in various conditions. Allows to use the playbook with inventory file that also contains other hosts/groups or even multiple clusters.
cluster_inventory_group:
  all: 'all'
  masters: 'masters'
  nodes: 'nodes'
  primary_master: 'primary-master'
  secondary_masters: 'secondary-masters'

#####
## PROXY
## proxy environment variable, mainly for fetching addons
#proxy_env:
#  http_proxy: 'http://proxy.corp.example.com:8080'
#  https_proxy: 'http://proxy.corp.example.com:8080'
#  no_proxy: '127.0.0.1,localhost,.example.com,.svc,.local,.localdomain,.internal,127.0.1.1,127.254.254.254,169.254.169.254,169.254.169.253,169.254.169.123,/var/run/docker.sock,.sock,sock,.socket'
#####

KUBERNETES_VERSION: "{{ KUBERNETES_VERSION_CUSTOM | default ('1.29.1') }}"
# Software versions (used by installation, package manager, image pull, etc. )

KEEPALIVED_VERSION: "1.3.5"
  # Use "1.3.*" if you want the latest 1.3 provided by your already defined package repositories
  # it's required only for HA
  # This value is not required when keepalived is run in docker (see networking.yaml)

#####
## PACKAGES (rpm/deb)
# kubernetes_repo_create: true # (default true) - triggers creation of /etc/repos.d/kubernetes.repo and similar for debian apt sources. 
##                        When disabled, the code expects repo will be available already on the system, before starting the plabook.

## Desired state for the yum packages (docker, kube*); it defaults to 'present'
## package_state: present # Other valid options for this context: latest
## (use latest only on OSes which have package managers that understand it (most do))
package_state: present #latest

PKGS_K8S_IO_CORE: "{{ PKGS_K8S_IO_CORE_CUSTOM | default ('https://pkgs.k8s.io/core') }}"

## when package_state: present and kube*_version params below are undefined, the playbook will not touch your kube* files, and you are in full control.
## kube* requires full_kube_reinstall set to True! (find it below) (due to ansible (pre 2.4), which does not downgrade packages, you need to uninstalling first)
## full_kube_apt_unhold is required when packages were put on hold previously.
kubeadm_version: "{{ KUBERNETES_VERSION }}*" #1.9.* #when undefined, it will not check it
kubelet_version: "{{ KUBERNETES_VERSION }}*" #1.9.* #when undefined, it will not check it
kubectl_version: "{{ KUBERNETES_VERSION }}*" #1.9.* #when undefined, it will not check it
# To find the possible versions, check: https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/filelists.xml
# curl -SL https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/filelists.xml | grep -A 1 'name="kubeadm' | grep ver
# curl -SL https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/filelists.xml | grep -A 1 'name="kubelet' | grep ver
# curl -SL https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64/repodata/filelists.xml | grep -A 1 'name="kubectl' | grep ver
#####
##### NOTE ->> For the actual k8s version, please set the below: ClusterConfiguration.kubernetesVersion

wait_charts_deploy_sanity: false #When defined, it will wait till all helm charts are fully working or fail before showing cluster-info

########## Image pre-pull on MASTERS (only)
## Usually pre-pull not required, but there is this option here.
## pre-pull is now done using kubeadm's pre-pull feature
## it will pre-pull from either images_repo defined below; if not defined, from registry.k8s.io
####
pre_pull_k8s_images: True
# pre_pull_k8s_images_ignore_errors: False
#####

####
## Docker images repo
## If you have your internal docker registry which proxies them (e.g. a nexus3 with docker proxy mirroring at least: registry.k8s.io,docker.io,quay.io), replace the value below.
# images_repo: "docker-registry-proxy.corp.example.com"
#####

## Images for prefetching when pre_pull_k8s_images is true and images_repo is defined
## They are pulled on primary-master only
## Now kubeadm does the pre-pull; Use this section only if really required for other images.
HOST_ARCH: amd64
#CALICO_VERSION: "v3.22.0"
DOCKER_IMAGES: [
  #{ name: "{{images_repo}}/calico/kube-controllers", tag: "{{ CALICO_VERSION }}" },
  #{ name: "{{images_repo}}/calico/apiserver", tag: "{{ CALICO_VERSION }}" },
  #{ name: "{{images_repo}}/calico/cni", tag: "{{ CALICO_VERSION }}" },
  #{ name: "{{images_repo}}/calico/pod2daemon-flexvol", tag: "{{ CALICO_VERSION }}" },
  #{ name: "{{images_repo}}/calico/node", tag: "{{ CALICO_VERSION }}" }
]

## How long to wait (in number of retries) for various sanity tests
## (usually bigger number is requried when network is slow and image pulls take long time)
RETRIES: 40

################################DONE HA

## When defined, it first forces uninstall any kube* packages (rpm/deb) from hosts
## When full_kube_reinstall is False or undefined, it will not reinstall # and it won't remove the /etc/kubernetes/ folder before reinstall
## Should be used only if a downgrade in kube* tools is required, otherwise it will waste a lot of time reinstalling unnecessary.
full_kube_reinstall: False # undefined is False. #Make it False for faster redeployments. Make true when you need downgrade (ansible does not downgrade rpms autoamtically)
                           # reinstall is set to True, kubectl, kubelet, kubeadm, kubernetes-cni will be uninstalled first
full_kube_apt_unhold: False # undefined is False. # use it together with full_kube_reinstall (usually in non-prod) when you want automatic unhold of packages on (debian based like ubuntu)
                            # unhold is required also when you define version for kube* packages, and packages were hold initially
etcd_clean: True # default is True, and it will cleanup /var/lib/etcd/ !
#####

#kubeadm_init_args: E.g.: "--skip-preflight-checks" 
#kubeadm_join_args: E.g.: "--skip-preflight-checks" 
# and/or "--discovery-token-unsafe-skip-ca-verification"
# and/or "--ignore-preflight-errors=all"

#######
## This will turn off your swap !!!
turn_swapoff: True #False # default True # Note: by default kubelet won't start if swap not disabled of or kubelet not instructed to accept swap on.

#####
## NTP SETUP
## it is mandatory to have the time from all machines in sync (especially for certs validity)
ntp_setup: False # when Chrony tasks will be ready, it will become default True
ntp_package: ntp # future: chrony
## ntp does not work via proxy, so, if ntp cannot reach external servers, define here the internal ntp server:
#ntp_conf: |
#  server ntp1.corp.example.com
#  server pool.ntp.org
#  server pool.ntp.org
#####

#####
## hostname fix: set_hostname_to_inventory_hostname
## to make sure the hostname in inventory (usually fqdn) is in sync with the hostname as seen inside the host (usually required by vangrant)
#set_hostname_to_inventory_hostname: True #False # Default False
#####

kernel_modules_setup: True # default: True
#It will load the required kernel modules like ip_vs, bridge, nf_conntrack_ipv4, br_netfilter ;  echo 1 >/proc/sys/net/bridge/bridge-nf-call-iptables

#####
docker_setup: "ignore" # when not defined, default is "auto"
  ## auto will install docker (if not yet installed), set it up (with overlay2 storage driver), (re)start it
  ## force will do the above even if it's already installed
  ## ignore will not check docker at all.
#####

#####
## Selinux
## If selinux_state is not defined, it will skip Selinux setup
## If values are defined, you may want to enable also "allow_restart"
#selinux_state: permissive #  OR: disabled # When undefined entire step is skipped
#selinux_policy: targeted  # defaults to targeted
#####

#####
## Allow restart (if required, e.g. if ansible's selinux module sets reboot_required to true,or if vsphere fix is required )
allow_restart: True ## Default False
#####

#####
## Iptables
iptables_setup: True # Default is True. 
# This is not ideal or perfect! Review code and decide. It will disable&mask firewalld service (if exists), set default policies ACCEPT, and it will remove REJECT rules from all chains (INPUT,FW,OUT) with a commands like: iptables -D INPUT -j REJECT --reject-with icmp-host-prohibited (for each). 
# If still issues, debug iptables on both master and nodes with: 
# watch -n1 iptables -vnL
# http://www.slsmk.com/how-to-log-iptables-dropped-packets-to-syslog/ and monitor with journalctl -kf
### # iptables_reset: False # False is default # Rarely used, this will be removed in the future
#####

#####
# reset_gracefully: False # False is default # Important if there was a cluster before and you want to shut it down using cordon and drain
#####

#####
## This is the configuration that will be used by kubeadm init on master.
## Structure comes from: https://kubernetes.io/docs/admin/kubeadm/#config-file

#####
## TAINTS (for master) & uncordon
## NoExecute evicts on the spot. (while NoSchedule does not allow new pods); other option: PreferNoSchedule
## FYI, by default, master has this taint: node-role.kubernetes.io/control-plane:NoSchedule
## If you want to be able to schedule pods on the master, either set master_uncordon:true  (prefered option) or via taints section: uncomment 'node-role.kubernetes.io/control-plane:NoSchedule-'
## It's useful if it's a single-machine Kubernetes cluster for development (replacing minikube)
## To see taints, use: kubectl describe nodes

#taints_master:
#- 'dedicated=control-plane:NoExecute'                 # Force eviction of pods from master
#- 'dedicated=control-plane:PreferNoSchedule'          # Safety net
#- 'dedicated:NoExecute-'                       # Puts the previous PreferNoSchedule into action - step1
#- 'node-role.kubernetes.io/control-plane:NoSchedule-' # Puts the previous PreferNoSchedule into action - step2
#####

taint_for_label:
- label: 'node-role.kubernetes.io/control-plane='
  taint: 'NoSchedule'
- label: 'node-role.kubernetes.io/infra='
  taint: 'PreferNoSchedule'

########## VARIOUS GENERIC SETTINGS #####
## This will be removed in the future versions:
# kubeadm_docker_insecure_registry: registry.example.com:5000
#####

#####
# BASH and ZSH aliases and cli completion
# shell for bash-completion for kubectl, kubeadm, helm; currently bash and zsh are supported (adding more is very simple)

aliases: # to disable adding aliases, comment out this entire section
  rc: local # local -> ~root/.bashrc && ~root/.zshrc # local is the default, if undefined
            # global -> '/etc/bash.bashrc' (ubuntu) '/etc/bashrc' (REDHAT); global -> '/etc/zshrc' (both ubuntu&RH)
            # custom -> see the below:
  rc_bash_custom: '/etc/profile.d/k8s_aliases.sh' # /etc/profile.d/*.sh location is sourced by all *sh, non-bash ones might not compatible with the generated file. Use with care.
  rc_zsh_custom: '/etc/zshrc' # /etc/profile.d/*.sh location is sourced by all *sh, non-bash ones might not compatible with the generated file. Use with care.
  file_create_if_missing: no # destination file will be created only if this is enabled. Otherwise the file will be updated only if exists.
  list:
  - "alias k='kubectl '"
  - "alias kf='kubectl delete --force --grace-period=0 --ignore-not-found '"
  - "alias kx='kubectl config use-context '"
  - "alias ks='kubectl -n kube-system '"
  - "alias km='kubectl -n monitoring '"
  - "alias kg='kubectl get --all-namespaces -o wide '" # --show-labels '"
  - "alias kgl='kubectl get --all-namespaces -o wide --show-labels '"
  - "alias kgp='kubectl get --all-namespaces -o wide --show-labels po '"
  - "alias kk='kubectl -o wide --show-labels '"
  - "alias watch='watch '"
  - "alias wp='watch kg po '" # -w --show-labels '"
  - "alias wipt='watch -n1 iptables -vnL '"
  - "alias hs='helm --namespace kube-system '"
  - "alias hm='helm --namespace monitoring '"
  - "alias hg='helm list --all --all-namespaces --pending '"
  kubectl_complete_also_aliases:
  - k
  - kf
  - kx
  - ks
  - km
  - kg
  - kk
  helm_complete_also_aliases:
  - hs
  - hm
  - hg

#####
